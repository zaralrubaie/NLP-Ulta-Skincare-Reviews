# -*- coding: utf-8 -*-
"""nlp-ulta-skincare-reviews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PRg_N01jzUjkwlGPM13cJlne6qheDAh_
"""

import pandas as pd
df=pd.read_csv('/kaggle/input/nlp-ulta-skincare-reviews/Ulta Skincare Reviews.csv')
df.head()

df=df.dropna()

import spacy
import re

def clean_text(text):
    cleaned = re.sub(r'[^a-zA-Z\s]', '', text)
    cleaned = cleaned.lower()
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned

# Apply function on the column
df['Review_Text'] = df['Review_Text'].apply(clean_text)
df['Review_Title'] = df['Review_Title'].apply(clean_text)

df.head(10)

nlp = spacy.load('en_core_web_sm')
import spacy


def clean_text(text):
    doc = nlp(text)
    tokens = [
        token.lemma_.lower()
        for token in doc
        if not token.is_stop
        and not token.is_punct
        and not token.is_space
        and not token.like_num
    ]
    return " ".join(tokens)
df['Review_Text'] = df['Review_Text'].apply(clean_text)
df['Review_Title'] = df['Review_Title'].apply(clean_text)

df.head()

def find_odd_symbols(text):
    if pd.isnull(text):  # Check for NaN
        return []
    return re.findall(r'[^a-zA-Z0-9\s]', text)

# Apply to Review_Title and Review_Text columns
df['odd_symbols_title'] = df['Review_Title'].apply(find_odd_symbols)
df['odd_symbols_text'] = df['Review_Text'].apply(find_odd_symbols)

# (Optional) Show rows that contain any odd symbols
df_with_odd = df[
    (df['odd_symbols_title'].str.len() > 0) |
    (df['odd_symbols_text'].str.len() > 0)
]

# View relevant columns
print(df_with_odd[['Review_Title', 'Review_Text', 'odd_symbols_title', 'odd_symbols_text']])

from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import hstack
# Initialize separate vectorizers
vectorizer_title = TfidfVectorizer()
vectorizer_text = TfidfVectorizer()

# Fit and transform each column
X_title = vectorizer_title.fit_transform(df['Review_Title'].fillna(''))
X_text = vectorizer_text.fit_transform(df['Review_Text'].fillna(''))

X_combined = hstack([X_title, X_text])

def convert_review_date(text):
    if pd.isna(text):
        return -1  # or np.nan
    num = int(re.search(r'\d+', text).group())
    if 'day' in text:
        return num
    elif 'month' in text:
        return num * 30
    elif 'year' in text:
        return num * 365
    else:
        return -1  # unknown format

df['Review_Date'] = df['Review_Date'].apply(convert_review_date)
df.head()

df['Scrape_Date'] = pd.to_datetime(df['Scrape_Date'], format='%m/%d/%y')

df['Scrape_Year'] = df['Scrape_Date'].dt.year
df['Scrape_Month'] = df['Scrape_Date'].dt.month
df['Scrape_Day'] = df['Scrape_Date'].dt.day
df['Scrape_Weekday'] = df['Scrape_Date'].dt.weekday  # Monday=0, Sunday=6
df=df.drop(['odd_symbols_text','odd_symbols_title','Scrape_Date','Brand','Review_Location'],axis=1)

#will encode normally
df.head()

product_map = {
    'Daily Superfoliant': 0,
    'Daily Microfoliant': 1,
    'Hydro Masque Exfoliant': 2,
    'Multi-Vitamin Thermafoliant': 3
}
df['Product'] = df['Product'].map(product_map)

verified_map = {'Yes': 1, 'No': 0}
df['Verified_Buyer'] = df['Verified_Buyer'].map(verified_map)

df.head()

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

def vader_sentiment(text):
    if not isinstance(text, str) or text.strip() == "":
        return 0
    score = analyzer.polarity_scores(text)['compound']
    return 1 if score > 0 else 0
df['Review_Text'] = df['Review_Text'].str.replace(r'\bexcelent\b', 'excellent', regex=True)

df['Sentiment'] = df['Review_Text'].apply(vader_sentiment)
df['Sentiment'].value_counts()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from scipy.sparse import hstack


y = df['Sentiment']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(class_weight='balanced')
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Create prediction table
prediction_table = pd.DataFrame({
    'Actual': y_test.values,
    'Predicted': y_pred
})
print("\nPrediction Table:")
print(prediction_table.head())